{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film = pd.read_csv(\"df_film.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajout données de tmdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ajouter des données telles que la popularité, les pays de production, les affiches de films, nous avons du nous servir du tmdb.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/s9b7316s21b6krxxntv4pzzm0000gn/T/ipykernel_1370/4031644567.py:1: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tmbd = pd.read_csv(\"tmdb_full.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_tmbd = pd.read_csv(\"tmdb_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmbd = df_tmbd.drop(columns = [\n",
    "    \"adult\",\n",
    "    \"backdrop_path\",\n",
    "    \"budget\",\n",
    "    \"genres\",\n",
    "    \"homepage\",\n",
    "    \"id\",\n",
    "    \"original_language\",\n",
    "    \"original_title\",\n",
    "    \"overview\",\n",
    "    \"release_date\",\n",
    "    \"revenue\",\n",
    "    \"runtime\",\n",
    "    \"spoken_languages\",\n",
    "    \"tagline\",\n",
    "    \"title\",\n",
    "    \"video\",\n",
    "    \"vote_average\",\n",
    "    \"vote_count\",\n",
    "    \"production_companies_name\",\n",
    "    \"production_companies_country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge nos nouvelles données avec le df_film "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0.2', 'Unnamed: 0.1', 'tconst'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fk/s9b7316s21b6krxxntv4pzzm0000gn/T/ipykernel_1370/3259251386.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_film\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df_film.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_merge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_film\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tmbd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"id_film\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"imdb_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_merge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_merge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Unnamed: 0.2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Unnamed: 0.1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Unnamed: 0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tconst\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4955\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4956\u001b[0m         \"\"\"\n\u001b[0;32m-> 4957\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4958\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4959\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4265\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4266\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4267\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4309\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4311\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4312\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6660\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6661\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6662\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6663\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Unnamed: 0.2', 'Unnamed: 0.1', 'tconst'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df_film = pd.read_csv(\"df_film.csv\")\n",
    "df_merge = df_film.merge(df_tmbd, left_on = \"id_film\", right_on = \"imdb_id\", how = \"left\")\n",
    "df_merge = df_merge.drop(columns = [\"Unnamed: 0.2\",\"Unnamed: 0.1\", \"Unnamed: 0\", \"tconst\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Créer des colonnes supplémentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer la colonne décénie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film[\"decenie\"] = ((df_film['année'] // 10) * 10).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remplacer des valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer les valeurs nulles en format compréhensible par python. Dans notre df actuellement les valeurs nulles sont des strings '\\\\N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film = df_film.replace('\\\\N', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Durée (temps_minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on veut remplacer les valeurs nulles par la moyenne des autres films de la même décénie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converti le temps (str) en int en contournant les valeurs nulles (fonctionne uniquement avec un type compris par python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film['temps_minutes'] = df_film['temps_minutes'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cacul de la moyenne par décénie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "moy_decenie = df_film.groupby(\"decenie\")[\"temps_minutes\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fonction qui remplace les valeurs nulles par la moyenne de la décénie à laquelle il appartient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacena_mean(row):\n",
    "    if str(row[\"temps_minutes\"]) == \"<NA>\":\n",
    "        row[\"temps_minutes\"] = moy_decenie.loc[row[\"decenie\"]]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer cette fonction\n",
    "df_film = df_film.apply(replacena_mean, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film.to_csv(\"df_film.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Années"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une liste de films qui ont pour année 0\n",
    "films_annee0 = df_film.loc[df_film[\"année\"] == 0, \"titre\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire avec les années manquantes au DF\n",
    "films = {\n",
    "    \"Shubh Kaamna\": 1983,\n",
    "    \"You Don't Know Nicotine\": 2020,\n",
    "    \"Becoming Led Zeppelin\": 2021,\n",
    "    \"Concorde, le rêve supersonique\": 2020,\n",
    "    \"Luccas Neto em: Acampamento de Férias\": 2019,\n",
    "    \"Luccas Neto em: Acampamento de Férias 2\": 2020,\n",
    "    \"Prem Prakaran\": 2021,\n",
    "    \"El Arribo de Conrado Sierra\": 2012,\n",
    "    \"Cyborg Nemesis: The Dark Rift\" : 2014,\n",
    "    \"90° South\" : 1933,\n",
    "    \"Samhain\" : 2021,\n",
    "    \"Haunted Connecticut\" : 2009,\n",
    "}\n",
    "\n",
    "# Apply du dictionnaire pour remplacer les valeurs manquantes\n",
    "df_film[\"année\"] = df_film.apply(lambda row: films.get(row[\"titre\"], row[\"année\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supression des lignes restantes avec année non renseignée\n",
    "df_film= df_film[df_film[\"année\"] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre les + vus par décénie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colonne genre contient une string avec plusieurs genres différents. Je veux dans un premier temps transformer ces chaînes de caractères en listes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour éviter les bugs avec split, je remplace les valeurs manquantes par des liste vides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film['genre'] = df_film['genre'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je créé donc une fonction qui va prendre la chaîne de caractère en paramètre et renvoyer la liste pour chaque ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfo_liste(chaine:str)-> list:\n",
    "    liste_genres = []\n",
    "    for genre in chaine.split(\",\"):\n",
    "        liste_genres.append(genre.strip())\n",
    "    return liste_genres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je l'applique sur la colonne que je veux. Ici, je transforme la colonne genre (initialement des strings) en une nouvelle colonne genre qui contient maintenant des listes de genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film['genre'] = df_film['genre'].apply(transfo_liste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, je voudrais compter les nombres de films de chaque genres par décénie. Pour ça je veux faire un dictionnaire qui à en clé la décénie, et en valeur, les nombres de films par genre [pour cette même décénie donc]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats_par_decennie = {}\n",
    "\n",
    "for decenie in df_film[\"decenie\"].unique():\n",
    "    df_dec = df_film.loc[df_film[\"decenie\"] == decenie, ['genre', 'decenie']].explode(\"genre\")\n",
    "    nb_genres = df_dec.groupby('genre')[\"genre\"].count()\n",
    "    resultats_par_decennie[decenie] = nb_genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je voudrais transformer ce dictionnaire en dataframe pour ensuite faire des visualisation graphiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genre_decenie = pd.DataFrame(resultats_par_decennie).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectif: heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif est de réaliser une heatmap (dans la partie analyse). Une heatmap qui prend en axe horizontal la décénie et en axe vertical les 10 genres les plus populaires. La couleur ne doit pas représenter le nombre de films brut mais plutôt le ratio que chaque genre représente par décénie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) On commence à travailler sur tout les genres (pas le top 10 pour l'instant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer le ration il faut faire = case / somme_colonne, on prendra les cases du dataframe top 10 qu'on divisera par la somme par colonne ce df plus global. On calcul donc la somme par colonne (par décénie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_par_dec = df_genre_decenie.sum(axis = 0) #calcul de la somme_colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pour le top 10, je fais une somme des genres que je trie par ordre croissant et desquels je ne garde que le top 10 (head10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genre_decenie[\"sum_genre\"] = df_genre_decenie.sum(axis = 1)\n",
    "df_top_genre = df_genre_decenie.sort_values(\"sum_genre\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je supprimme ensuite la colonne sum_genre qui ne servait qu'à créer ce nouveau dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_genre = df_top_genre.drop(columns = 'sum_genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant je fais le ratio avec la somme par colonne du dataframe total (sans le filtre du top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_genre = df_top_genre / sum_par_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_genre.to_csv(\"df_top_genre.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meilleur score pays producteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir liste pays\n",
    "def convertir_en_liste(x):\n",
    "    if isinstance(x, str):  # Si c'est une chaîne\n",
    "        return ast.literal_eval(x)  # Convertir en liste Python\n",
    "    return x  # Retourner inchangé si ce n'est pas une chaîne\n",
    "\n",
    "df_film[\"production_countries\"] = df_film[\"production_countries\"].apply(convertir_en_liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode en DF Pays / nb_film\n",
    "df_exploded = df_film.explode(\"production_countries\")\n",
    "nb_films_pays = df_exploded[\"production_countries\"].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename colonne\n",
    "nb_films_pays = nb_films_pays.rename(columns={\"production_countries\" :\"nb_films\", \"index\": \"pays\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode en DF pays/popu\n",
    "pop_pays = df_exploded.groupby(\"production_countries\")[\"popularity\"].mean().sort_values(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename colonne\n",
    "pop_pays = pop_pays.rename(columns={\"production_countries\" :\"pays\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge nb_films_pays et pop_pays\n",
    "df_score = nb_films_pays.merge(pop_pays, left_on=[\"pays\"], right_on=[\"pays\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyenne de film par pays\n",
    "moy_nb_film = df_score[\"nb_films\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer le score\n",
    "def score(row):\n",
    "    return 0.2 + (min(moy_nb_film, row[\"nb_films\"]) / moy_nb_film) * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply de la fonction dans la nouvelle colonne ratio\n",
    "df_score[\"ratio\"] = df_score.apply(score,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouvel colonne score avec le calcul ratio\n",
    "df_score[\"score\"] = df_score[\"popularity\"] * df_score[\"ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 15 pays\n",
    "df_score = df_score.sort_values(\"score\", ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire de correspondance code -> pays\n",
    "pays = {\n",
    "    \"US\": \"États-Unis\",\n",
    "    \"GB\": \"Royaume-Uni\",\n",
    "    \"IE\": \"Irlande\",\n",
    "    \"KR\": \"Corée du Sud\",\n",
    "    \"CA\": \"Canada\",\n",
    "    \"AU\": \"Australie\",\n",
    "    \"BE\": \"Belgique\",\n",
    "    \"JP\": \"Japon\",\n",
    "    \"CN\": \"Chine\",\n",
    "    \"NZ\": \"Nouvelle-Zélande\",\n",
    "    \"ES\": \"Espagne\",\n",
    "    \"FR\": \"France\",\n",
    "    \"NO\": \"Norvège\",\n",
    "    \"HK\": \"Hong Kong\",\n",
    "    \"NL\": \"Pays-Bas\",\n",
    "    \"DE\": \"Allemagne\",\n",
    "    \"CZ\": \"République tchèque\",\n",
    "    \"IT\": \"Italie\",\n",
    "    \"MX\": \"Mexique\",\n",
    "    \"TH\": \"Thaïlande\"\n",
    "}\n",
    "# Apply du nom du pays au lieu du code\n",
    "df_score[\"pays\"] = df_score[\"pays\"].map(pays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pays = df_score.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pays.to_csv(\"Top_pays.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meilleure score réalisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by + agg\n",
    "top_real = (\n",
    "    df_film.groupby(\"Real\")\n",
    "    .agg({\"titre\": \"count\", \"nb_votes\": \"sum\", \"note\": \"mean\"})\n",
    "    .sort_values(by=\"titre\", ascending=False) \n",
    "    .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename colonne\n",
    "top_real = top_real.rename(columns={\"titre\" :\"nb_films\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyenne de nombre de votes\n",
    "moy_vote = df_film[\"nb_votes\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyenne de nombre de film\n",
    "moy_nb_film_real = top_real[\"nb_films\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer le score\n",
    "def real2(row):\n",
    "    return ((((min(1000000, row[\"nb_votes\"]) / 1000000) * 0.3) + ((min(10, row[\"nb_films\"]))/ 10) * 0.4) + 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouvelle colonne avec colonne ratio\n",
    "top_real[\"ratio\"] = top_real.apply(real2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouvelle colonne avec le score\n",
    "top_real[\"score\"] = top_real[\"note\"] * top_real[\"ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 real\n",
    "top10_real = top_real.sort_values(\"score\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export \n",
    "top10_real.to_csv(\"top10_real_note.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer le score\n",
    "def real2(row):\n",
    "    return ((((min(1000000, row[\"nb_votes\"]) / 1000000) * 0.3) + ((min(10, row[\"nb_films\"]))/ 10) * 0.4) + 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse avec d'autre filtres\n",
    "top_real2 = top_real\n",
    "top_real2[\"ratio\"] = top_real2.apply(real2,axis=1)\n",
    "top_real2[\"score\"] = top_real2[\"note\"] * top_real2[\"ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10\n",
    "top10_real2 = top_real2.sort_values(\"score\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export CSV\n",
    "top10_real2.to_csv(\"top10_real_note2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
